<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>http://andife.github.io/onnx.github.io/videos/</title><link href="https://andife.github.io/onnx.github.io/docs/" rel="alternate"></link><link href="https://andife.github.io/onnx.github.io/docs/feeds/tag_quantization.atom.xml" rel="self"></link><id>https://andife.github.io/onnx.github.io/docs/</id><updated>2021-10-24T00:00:00+00:00</updated><entry><title>Quantization support for ONNX using Intel Neural Compressor (formerly named Intel Low Precision Optimization Tool)</title><link href="https://andife.github.io/onnx.github.io/docs/onnx-community-day-2021_03/quantization-support-for-onnx-using-intel-neural-compressor-formerly-named-intel-low-precision-optimization-tool.html" rel="alternate"></link><updated>2021-03-10T00:00:00+00:00</updated><author><name>Haihao Shen (Intel - China)</name></author><id>tag:andife.github.io,2021-03-10:onnx.github.io/docs/onnx-community-day-2021_03/quantization-support-for-onnx-using-intel-neural-compressor-formerly-named-intel-low-precision-optimization-tool.html</id><summary type="html"></summary><category term="intel"></category><category term="quantization"></category></entry><entry><title>Spring Projectï¼šMulti Backend Neural Network Auto Quantization and Deployment over ONNX</title><link href="https://andife.github.io/onnx.github.io/docs/onnx-community-day-2021_03/spring-projectmulti-backend-neural-network-auto-quantization-and-deployment-over-onnx.html" rel="alternate"></link><updated>2021-03-10T00:00:00+00:00</updated><author><name>Fengwei Yu (SenseTime-China)</name></author><id>tag:andife.github.io,2021-03-10:onnx.github.io/docs/onnx-community-day-2021_03/spring-projectmulti-backend-neural-network-auto-quantization-and-deployment-over-onnx.html</id><summary type="html"></summary><category term="Quantization"></category></entry><entry><title>Intel Neural Compressor: A Scalable Quantization Tool for ONNX Models</title><link href="https://andife.github.io/onnx.github.io/docs/onnx-community-day-2021_10/intel-neural-compressor-a-scalable-quantization-tool-for-onnx-models.html" rel="alternate"></link><updated>2021-10-24T00:00:00+00:00</updated><author><name>Mengni Wang (Intel)</name></author><id>tag:andife.github.io,2021-10-24:onnx.github.io/docs/onnx-community-day-2021_10/intel-neural-compressor-a-scalable-quantization-tool-for-onnx-models.html</id><summary type="html"></summary><category term="Intel"></category><category term="INC"></category><category term="Quantization"></category></entry></feed>