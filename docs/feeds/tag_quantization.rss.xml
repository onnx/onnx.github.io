<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>http://andife.github.io/onnx.github.io/videos/</title><link>https://andife.github.io/onnx.github.io/</link><description></description><atom:link href="https://andife.github.io/onnx.github.io/feeds/tag_quantization.rss.xml" rel="self"></atom:link><lastBuildDate>Sun, 24 Oct 2021 00:00:00 +0000</lastBuildDate><item><title>Quantization support for ONNX using Intel Neural Compressor (formerly named Intel Low Precision Optimization Tool)</title><link>https://andife.github.io/onnx.github.io/onnx-community-day-2021_03/quantization-support-for-onnx-using-intel-neural-compressor-formerly-named-intel-low-precision-optimization-tool.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Haihao Shen (Intel - China)</dc:creator><pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate><guid>tag:andife.github.io,2021-03-10:onnx.github.io/onnx-community-day-2021_03/quantization-support-for-onnx-using-intel-neural-compressor-formerly-named-intel-low-precision-optimization-tool.html</guid><category>intel</category><category>quantization</category></item><item><title>Spring Projectï¼šMulti Backend Neural Network Auto Quantization and Deployment over ONNX</title><link>https://andife.github.io/onnx.github.io/onnx-community-day-2021_03/spring-projectmulti-backend-neural-network-auto-quantization-and-deployment-over-onnx.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Fengwei Yu (SenseTime-China)</dc:creator><pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate><guid>tag:andife.github.io,2021-03-10:onnx.github.io/onnx-community-day-2021_03/spring-projectmulti-backend-neural-network-auto-quantization-and-deployment-over-onnx.html</guid><category>Quantization</category></item><item><title>Intel Neural Compressor: A Scalable Quantization Tool for ONNX Models</title><link>https://andife.github.io/onnx.github.io/onnx-community-day-2021_10/intel-neural-compressor-a-scalable-quantization-tool-for-onnx-models.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mengni Wang (Intel)</dc:creator><pubDate>Sun, 24 Oct 2021 00:00:00 +0000</pubDate><guid>tag:andife.github.io,2021-10-24:onnx.github.io/onnx-community-day-2021_10/intel-neural-compressor-a-scalable-quantization-tool-for-onnx-models.html</guid><category>Intel</category><category>INC</category><category>Quantization</category></item></channel></rss>