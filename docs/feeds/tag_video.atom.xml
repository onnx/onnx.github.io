<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>http://andife.github.io/onnx.github.io/videos/</title><link href="https://andife.github.io/onnx.github.io/" rel="alternate"></link><link href="https://andife.github.io/onnx.github.io/feeds/tag_video.atom.xml" rel="self"></link><id>https://andife.github.io/onnx.github.io/</id><updated>2022-06-24T00:00:00+00:00</updated><entry><title>High-Performance Inference for Video and Audio</title><link href="https://andife.github.io/onnx.github.io/onnx-community-day-2022_06/high-performance-inference-for-video-and-audio.html" rel="alternate"></link><updated>2022-06-24T00:00:00+00:00</updated><author><name>Nikhil Kalra (Adobe )</name></author><id>tag:andife.github.io,2022-06-24:onnx.github.io/onnx-community-day-2022_06/high-performance-inference-for-video-and-audio.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;ORT provides the foundations for inference for Adobe's audio and video products (Premiere Pro, After Effects, Character Animator) on both Mac and Windows. In this talk, we'll discuss how ORT with the DML backend is essential in enabling high-throughput inference for audio and video workflows on Windows, and how we use ORT to enable speech to text on Mac. Video workflows are unique because of the sheer amount of data they process; our customers frequently ingest high resolution video &amp;gt;= &lt;a class="reference external" href="mailto:4k&amp;#64;60fps"&gt;4k&amp;#64;60fps&lt;/a&gt; of which each frame may need to be passed through our models. Likewise, video workflows are inherently resource limited: the GPU is also being used for hardware decode and render at the same time. ORT gives us the tools to build complex frameworks and workflows on top of so that we can deliver ML-based features while ensuring that we're able to provide the best experience for our customers.&lt;/p&gt;
</summary><category term="High-performance"></category><category term="video"></category><category term="audio"></category></entry></feed>