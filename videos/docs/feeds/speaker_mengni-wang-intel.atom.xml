<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>https://onnx.ai/media/</title><link href="/" rel="alternate"></link><link href="/feeds/speaker_mengni-wang-intel.atom.xml" rel="self"></link><id>/</id><updated>2021-10-24T00:00:00+00:00</updated><entry><title>Intel Neural Compressor: A Scalable Quantization Tool for ONNX Models</title><link href="/onnx-community-day-2021_10/intel-neural-compressor-a-scalable-quantization-tool-for-onnx-models.html" rel="alternate"></link><updated>2021-10-24T00:00:00+00:00</updated><author><name>Mengni Wang (Intel)</name></author><id>tag:,2021-10-24:onnx-community-day-2021_10/intel-neural-compressor-a-scalable-quantization-tool-for-onnx-models.html</id><summary type="html"></summary><category term="Intel"></category><category term="INC"></category><category term="Quantization"></category></entry></feed>