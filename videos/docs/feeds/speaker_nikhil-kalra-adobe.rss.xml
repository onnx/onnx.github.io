<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>https://onnx.ai/media/</title><link>/</link><description></description><atom:link href="/feeds/speaker_nikhil-kalra-adobe.rss.xml" rel="self"></atom:link><lastBuildDate>Fri, 24 Jun 2022 00:00:00 +0000</lastBuildDate><item><title>High-Performance Inference for Video and Audio</title><link>/onnx-community-day-2022_06/high-performance-inference-for-video-and-audio.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;ORT provides the foundations for inference for Adobe's audio and video products (Premiere Pro, After Effects, Character Animator) on both Mac and Windows. In this talk, we'll discuss how ORT with the DML backend is essential in enabling high-throughput inference for audio and video workflows on Windows, and how we use ORT to enable speech to text on Mac. Video workflows are unique because of the sheer amount of data they process; our customers frequently ingest high resolution video &amp;gt;= &lt;a class="reference external" href="mailto:4k&amp;#64;60fps"&gt;4k&amp;#64;60fps&lt;/a&gt; of which each frame may need to be passed through our models. Likewise, video workflows are inherently resource limited: the GPU is also being used for hardware decode and render at the same time. ORT gives us the tools to build complex frameworks and workflows on top of so that we can deliver ML-based features while ensuring that we're able to provide the best experience for our customers.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Nikhil Kalra (Adobe )</dc:creator><pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate><guid>tag:,2022-06-24:onnx-community-day-2022_06/high-performance-inference-for-video-and-audio.html</guid><category>High-performance</category><category>video</category><category>audio</category></item></channel></rss>