<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>https://onnx.ai/media/</title><link>/</link><description></description><atom:link href="/feeds/speaker_rajeev-nalawadi-intel.rss.xml" rel="self"></atom:link><lastBuildDate>Fri, 24 Jun 2022 00:00:00 +0000</lastBuildDate><item><title>SteeringCommitteeUpdates: ONNX Steering Committee Welcome, Progress, Roadmap, Release</title><link>/onnx-community-day-2021_10/steeringcommitteeupdates-onnx-steering-committee-welcome-progress-roadmap-release.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Prasanth Pulavarthi (Microsoft)</dc:creator><pubDate>Sun, 24 Oct 2021 00:00:00 +0000</pubDate><guid>tag:,2021-10-24:onnx-community-day-2021_10/steeringcommitteeupdates-onnx-steering-committee-welcome-progress-roadmap-release.html</guid><category>Steering Committee</category><category>Roadmap</category></item><item><title>ONNX Steering Committee Update</title><link>/onnx-community-day-2022_06/onnx-steering-committee-update.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Prasanth Pulavarthi (Microsoft)</dc:creator><pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate><guid>tag:,2022-06-24:onnx-community-day-2022_06/onnx-steering-committee-update.html</guid><category>Steering Committee</category></item><item><title>Responsible AI @ ONNX: Metadata, Model Cards, and Provenance</title><link>/onnx-community-day-2022_06/responsible-ai-onnx-metadata-model-cards-and-provenance.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The space of AI is growing rapidly. At this pace, it can be challenging for key AI stakeholders to identify and address social and regulatory concerns with AI, motivating the need for tools and methods to approach AI ethics challenges. A popular approach in the responsible AI space is using metadata to encode a “model card,” a versatile report detailing the configuration, ethical considerations, limitations, and quantitative analysis of an AI model. This approach can be used to enable transparency and fairness of the use case, filtering of high-quality AI models, pain point identification in AI pipelines, and help with establishing compliance and lineage. In this session, we will present our proposal and end-to-end proof of concept for metadata fields and model cards incorporated in Onnx to capture aspects of the model such as provenance &amp;amp; mixed precision representation.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rodolfo Gabe Esteves (Intel)</dc:creator><pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate><guid>tag:,2022-06-24:onnx-community-day-2022_06/responsible-ai-onnx-metadata-model-cards-and-provenance.html</guid><category>responsible AI</category></item></channel></rss>