<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>https://onnx.ai/media/</title><link>/</link><description></description><atom:link href="/feeds/speaker_saurabh-tangri-intel.rss.xml" rel="self"></atom:link><lastBuildDate>Wed, 10 Mar 2021 00:00:00 +0000</lastBuildDate><item><title>Quantization support for ONNX using Intel Neural Compressor (formerly named Intel Low Precision Optimization Tool)</title><link>/onnx-community-day-2021_03/quantization-support-for-onnx-using-intel-neural-compressor-formerly-named-intel-low-precision-optimization-tool.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Haihao Shen (Intel - China)</dc:creator><pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate><guid>tag:,2021-03-10:onnx-community-day-2021_03/quantization-support-for-onnx-using-intel-neural-compressor-formerly-named-intel-low-precision-optimization-tool.html</guid><category>intel</category><category>quantization</category></item></channel></rss>