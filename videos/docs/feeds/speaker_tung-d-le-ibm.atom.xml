<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>https://onnx.ai/media/</title><link href="/" rel="alternate"></link><link href="/feeds/speaker_tung-d-le-ibm.atom.xml" rel="self"></link><id>/</id><updated>2022-06-24T00:00:00+00:00</updated><entry><title>Onnx-mlir: an MLIR-based Compiler for ONNX Models - The Latest Status</title><link href="/onnx-community-day-2022_06/onnx-mlir-an-mlir-based-compiler-for-onnx-models-the-latest-status.html" rel="alternate"></link><updated>2022-06-24T00:00:00+00:00</updated><author><name>Tung D. Le (IBM)</name></author><id>tag:,2022-06-24:onnx-community-day-2022_06/onnx-mlir-an-mlir-based-compiler-for-onnx-models-the-latest-status.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Onnx-mlir is an open source compiler implemented using the Multi-Level Intermediate Representation (MLIR) infrastructure recently integrated in the LLVM project. It compiles ONNX models into native code for CPUs as well as specialized accelerators. It is able to compile models for many platforms including x86 (Linux/Windows/macOS), Power (Linux) and z/Architecture (Linux and z/OS). Onnx-mlir is a subproject inside the ONNX ecosystem and has attracted many contributions from IBM, Microsoft, Facebook, Arm and Universities since its incubation in 2019. In this talk, we will show the latest status of the project by providing the project overview as well as the latest features.&lt;/p&gt;
</summary><category term="mlir"></category></entry></feed>