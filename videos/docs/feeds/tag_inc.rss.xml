<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>https://onnx.ai/media/</title><link>/</link><description></description><atom:link href="/feeds/tag_inc.rss.xml" rel="self"></atom:link><lastBuildDate>Sun, 24 Oct 2021 00:00:00 +0000</lastBuildDate><item><title>Intel Neural Compressor: A Scalable Quantization Tool for ONNX Models</title><link>/onnx-community-day-2021_10/intel-neural-compressor-a-scalable-quantization-tool-for-onnx-models.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mengni Wang (Intel)</dc:creator><pubDate>Sun, 24 Oct 2021 00:00:00 +0000</pubDate><guid>tag:,2021-10-24:onnx-community-day-2021_10/intel-neural-compressor-a-scalable-quantization-tool-for-onnx-models.html</guid><category>Intel</category><category>INC</category><category>Quantization</category></item></channel></rss>