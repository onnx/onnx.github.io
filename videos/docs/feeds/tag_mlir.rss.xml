<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>https://onnx.ai/media/</title><link>/</link><description></description><atom:link href="/feeds/tag_mlir.rss.xml" rel="self"></atom:link><lastBuildDate>Fri, 24 Jun 2022 00:00:00 +0000</lastBuildDate><item><title>Onnx-mlir: an MLIR-based Compiler for ONNX Models - The Latest Status</title><link>/onnx-community-day-2022_06/onnx-mlir-an-mlir-based-compiler-for-onnx-models-the-latest-status.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Onnx-mlir is an open source compiler implemented using the Multi-Level Intermediate Representation (MLIR) infrastructure recently integrated in the LLVM project. It compiles ONNX models into native code for CPUs as well as specialized accelerators. It is able to compile models for many platforms including x86 (Linux/Windows/macOS), Power (Linux) and z/Architecture (Linux and z/OS). Onnx-mlir is a subproject inside the ONNX ecosystem and has attracted many contributions from IBM, Microsoft, Facebook, Arm and Universities since its incubation in 2019. In this talk, we will show the latest status of the project by providing the project overview as well as the latest features.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tung D. Le (IBM)</dc:creator><pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate><guid>tag:,2022-06-24:onnx-community-day-2022_06/onnx-mlir-an-mlir-based-compiler-for-onnx-models-the-latest-status.html</guid><category>mlir</category></item></channel></rss>